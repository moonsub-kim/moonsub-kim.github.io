---
title: FoundationDB (SIGMOD '21)
parent: Distributed Systems
last_modified_date: 2022-06-09
nav_order: 12
description: "Appleì˜ [FoundationDB: A Distributed Unbundled Transactional Key Value Store (SIGMOD â€˜21)](https://www.foundationdb.org/files/fdb-paper.pdf) ë¥¼ ë²ˆì—­í•œ ê¸€ ì…ë‹ˆë‹¤."
---
**{{ page.description }}**

[https://www.foundationdb.org/blog/fdb-paper/](https://www.foundationdb.org/blog/fdb-paper/)

# FoundationDB: A Distributed Unbundled Transactional Key Value Store (SIGMOD â€˜21)

## 1. Introduction

NoSQLì— transactionì„ ì–¹ì—ˆë‹¤. consistent secondary index, referential integrity checkë¥¼ ì§€ì›í•œë‹¤. FoundationDBëŠ” ì „ì²´ key spaceì—ì„œ serializable transactionì„ ì§€ì›í•˜ëŠ” ordered, transactional, key-value storeì´ë‹¤. ê¸°ì¡´ DBê°€ storage engine, data model, query languageë¥¼ í•œêº¼ë²ˆì— ì œê³µí•˜ëŠ” ë°˜ë©´ FDBëŠ” modular approachë¡œ ì ‘ê·¼í–ˆë‹¤. FDBëŠ” ìµœì†Œí•œì˜ ê¸°ëŠ¥ë§Œ ë„£ì–´ì„œ highly scalableí•œ transaction storage engineì„ ì œê³µí•œë‹¤. transactional dbì—ì„œ ì œê³µí•˜ëŠ” structured semantic, query languageëŠ” ì—†ê³ , data model, schema management, secondary indexëŠ” ì œê³µí•œë‹¤.

FDBê°€ open sourceë¡œ ì„±ì¥í• ìˆ˜ ìˆì—ˆë˜ê±´ FDBê°€ foundationì—ë§Œ ì§‘ì¤‘í–ˆê¸° ë•Œë¬¸ì´ë‹¤. ì´ë¥¼ í†µí•´ ë‹¤ë¥¸ ì¢…ë¥˜ì˜ storage systemì´ í•„ìš”í–ˆë˜ applicationì—ì„œ FDBë¥¼ ì“¸ìˆ˜ ìˆì—ˆë‹¤. ì‹¤ì œë¡œ ìµœê·¼ ëª‡ë…„ê°„ FDBìœ„ì— ì˜¬ë¼ê°€ëŠ” ë§ì€ layer ìƒê²¼ë‹¤. [FoundationDB Record Layer](https://arxiv.org/pdf/1901.04452.pdf) ëŠ” ê¸°ì¡´ ìœ ì €ê°€ RDBì—ì„œ í•„ìš”ë¡œ í•˜ë˜ê²ƒë“¤ì„ ì¶”ê°€í–ˆë‹¤. CouchDB ì²« NoSQLì¸ë° Foundation DB ê¸°ë°˜ìœ¼ë¡œ ì¬ì‘ì„±ë˜ì—ˆë‹¤.

distributed systemì„ í…ŒìŠ¤íŠ¸, ë””ë²„ê·¸í•˜ëŠ”ê±´ ì´ systemì„ ë§Œë“œëŠ” ê²ƒ ë§Œí¼ì´ë‚˜ ì–´ë µë‹¤. unexpected process, network failure, message reorderingê³¼ ë‹¤ë¥¸ non-determinismì€ ë²„ê·¸ë¥¼ ë§Œë“¤ê³ , ì½”ë“œì— ìˆë˜ implicití•œ ê°€ì •ë“¤ì„ ê¹¨ë²„ë¦¬ëŠ”ë° ì´ëŸ°ê²ƒë“¤ì€ ë””ë²„ê¹…ì´ë‚˜ reproduceê°€ ì–´ë µë‹¤. ë˜í•œ DBì˜ stateful natureëŠ” ë²„ê·¸ê°€ ìƒê²¼ì„ë•Œ data corruptionì´ ìƒê¸¸ ìˆ˜ ìˆê³  ëª‡ê°œì›”ë™ì•ˆ ë°œê²¬í•˜ì§€ ëª»í•  ìˆ˜ë„ìˆë‹¤. Model checkingì€ distributed protocolì˜ ì •í™•ì„±ì„ í™•ì¸í•  ìˆ˜ ìˆì§€ë§Œ, ì‹¤ì œ êµ¬í˜„ì„ í™•ì¸í•˜ê¸°ëŠ” ì–´ë µë‹¤. íŠ¹ì • ì‹œí€€ìŠ¤ì—ì„œ multiple crash/restartê°€ ë°œìƒí• ë•Œ ìƒê¸°ëŠ” [Deep bugs](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-leesatapornwongsa.pdf) ëŠ” end-to-end testing infraì—ì„œë„ ë¬¸ì œê°€ ëœë‹¤. FDBëŠ” DBë¥¼ ê°œë°œí•˜ê¸° ì „ì— processë“¤ì´ ìƒí˜¸ì‘ìš©í•˜ëŠ” networkì™€ disk, process, network, request-level failure/recoveryë“± ëª¨ë“ ê²ƒì„ í•˜ë‚˜ì˜ physical processì—ì„œ simulateí•˜ëŠ” deterministic DB simulation frameworkë¥¼ ë§Œë“¤ì—ˆë‹¤. ì´ë¥¼ í†µí•´ FDBê°€ stableí•˜ê³  ê°œë°œìë“¤ì´ ì‰½ê²Œ ìƒˆ featureë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆì—ˆë‹¤.

FDBëŠ” control planeê³¼ data planeìœ¼ë¡œ êµ¬ì„±ë˜ëŠ” [unbundled architecture](https://database.cs.wisc.edu/cidr/cidr2009/Paper_53.pdf)ë¥¼ ì ìš©í–ˆë‹¤. control planeì€ clusterì˜ metadataë¥¼ ê´€ë¦¬í•˜ê³  HAë¥¼ ìœ„í•´ Active Disk Paxosë¥¼ ì“´ë‹¤. data planeì€ updateë¥¼ ì±…ì„ì§€ëŠ” transaction management systemê³¼ read requestë¥¼ ë°›ëŠ” distributed storage layerë¡œ êµ¬ì„±ëœë‹¤. transaction management systemê³¼ distributed storage layerëŠ” ë…ë¦½ì ìœ¼ë¡œ scale-out ê°€ëŠ¥í•˜ë‹¤. FDBëŠ” OCC(Optimistic Concurrency Control)ê³¼ MVCC(Multi-Version Concurrency Control)ì„ ì¡°í•©í•˜ì—¬ strict serializabilityë¥¼ ì œê³µí•œë‹¤. lock-free architecture(OCC+MVCC ì´ë¯€ë¡œ) ì™¸ì—ë„ ë‹¤ë¥¸ DBì™€ êµ¬ë¶„ë˜ëŠ” featureì¤‘ í•˜ë‚˜ëŠ” failureë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì´ë‹¤. FDBëŠ” failureë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ quorumì„ ì“°ì§€ ì•Šê³  reconfiguringì„ í†µí•´ eagerí•˜ê²Œ failureë¥¼ ì°¾ê³  recoverí•˜ë ¤ ì‹œë„í•œë‹¤. ì´ê±´ í›¨ì”¬ ë” ì ì€ resourceë¡œ fault toleranceë¥¼ ì œê³µí•´ì¤€ë‹¤. FDBëŠ” $f + 1$ê°œì˜ replicaê°€ ìˆì„ë•Œ $f$ failureê¹Œì§€ tolerantí•˜ë‹¤ (ë‹¤ë¥¸ distributed systemì€ $f$ failureê¹Œì§€ tolerantí•˜ë ¤ë©´ quorumë•Œë¬¸ì— $2f+ 1$ê°œ replicaê°€ í•„ìš”í•¨). ì´ ë°©ì‹ì€ ë„ì‹œë‹¨ìœ„ì˜ deploymentì—ì„œ ì í•©í•˜ë‹¤. WAN deploymentì—ì„œ FDBëŠ” data lossì—†ì´ regionê°„ automatic failoverë¥¼ ì œê³µí•˜ë©´ì„œë„ cross-region write latencyë¥¼ í”¼í•œë‹¤.

## 2. Design

### 2.1 Design Principles

- Divide-and-Conquer
FDBëŠ” transaction management system (write path)ì™€ distributed storage (read path)ë¥¼ ë¶„ë¦¬í•˜ê³  ê°ê°ì„ ë…ë¦½ì ìœ¼ë¡œ scale in/outí•  ìˆ˜ ìˆê²Œ í–ˆë‹¤. transaction management systemì˜ processë“¤ì€ transaction management, conflict detection, logging, timestamp management, accepting commit ë“±ì˜ ë‹¤ì–‘í•œ roleì„ í• ë‹¹ë°›ëŠ”ë‹¤. ë˜í•œ overload control, load balancing, failure recoveryê°™ì€ cluster-wide taskë„ heterogeneous roleë¡œ ë‚˜ëˆ„ì–´ì§„ë‹¤.
- Make failure a common case
distributed systemì—ì„œ failureëŠ” ì¼ë°˜ì ì´ë‹¤. FDBì˜ transaction systemì€ ëª¨ë“  failureì— ëŒ€í•´, ê°€ëŠ¥í•œ ëª¨ë“  failure scenarioì— ëŒ€ì‘í•˜ëŠ”ê²Œ ì•„ë‹ˆë¼ recovery pathë¥¼ í†µí•´ ì²˜ë¦¬í•œë‹¤. ë”°ë¼ì„œ ëª¨ë“  failureëŠ” well-tested code pathì¸ recovery operation í•˜ë‚˜ë§Œìœ¼ë¡œ ì²˜ë¦¬ëœë‹¤. ì´ëŸ° ì—ëŸ¬ í•¸ë“¤ë§ ë°©ì‹ì€ recoveryê°€ ë¹ ë¥´ê²Œ ì¼ì–´ë‚˜ì¤˜ì•¼í•˜ê³  normal transaction processingë„ ë‹¨ìˆœí•´ì•¼ í•œë‹¤.
- Fail fast and recover fast
availabilityë¥¼ ë†’ì´ê¸° ìœ„í•´ FDBëŠ” failureë¥¼ ê°ì§€í•˜ê³ ë¶€í„° transaction management systemì„ shutdownì‹œí‚¨ë’¤ recoverí• ë•Œê¹Œì§€ì˜ MTTR(Mean Time To Recovery)ì„ ìµœì†Œí™”í•˜ëŠ”ë° ì§‘ì¤‘í–ˆë‹¤. production clusterì—ì„œ MTTRì€ ëŒ€ëµ 5ì´ˆ ì´ë‚´ì´ë‹¤ (Section 5.3)
- Simulation testing
FDBëŠ” correctness testë¥¼ ìœ„í•´ randomized, deterministic simulation frameworkë¥¼ ì‚¬ìš©í•œë‹¤. simulation testëŠ” [deep bugs](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-leesatapornwongsa.pdf)ë¥¼ ì¡ì„ë¿ë§Œì•„ë‹ˆë¼ FDBì˜ ê°œë°œ ìƒì‚°ì„±, ì½”ë“œ í€„ë¦¬í‹°ë¥¼ ë†’ì¸ë‹¤.

### 2.2 System Interface

FDBëŠ” $get(), set(), getRange(), clear()$ ë©”ì†Œë“œë¥¼ ì œê³µí•œë‹¤. $clear()$ëŠ” íŠ¹ì • key prefixë¥¼ ê°€ì§€ëŠ” ëª¨ë“  KV pairë¥¼ ì‚­ì œí•œë‹¤.
FDB transactionì€ íŠ¹ì • versionì˜ DB snapshotì„ ë³´ê³  ìˆ˜ì •í•˜ê³ , transactionì´ commitë ë•Œë§Œ changeë¥¼ DBì— ë°˜ì˜í•œë‹¤. transactional write ($set(), clear()$)ëŠ” $commit()$ì´ í˜¸ì¶œë˜ê¸° ì „ê¹Œì§€ FDB clientì— bufferë˜ê³ , read-your-write semanticì€ transactionì•ˆì—ì„œ DBë¥¼ ì¡°íšŒí•œ ê²°ê³¼ì™€ transactionì˜ uncommitted writeë¥¼ í•©ì³ì„œ ìœ ì§€í•œë‹¤. ì„±ëŠ¥ì„ ìœ„í•´ KeyëŠ” 10KB, ValueëŠ” 100KBê¹Œì§€ ê°€ëŠ¥í•˜ë‹¤. Transaction sizeëŠ” ëª¨ë“  writeëœ key valueì˜ í¬ê¸°ì™€, read/writeì´ conflict rangeì— ì†í•˜ëŠ” ëª¨ë“  keyì˜ í¬ê¸°ë¥¼ í¬í•¨í•´ì„œ ìµœëŒ€ 10MBì´ë‹¤.

### 2.3 Architecture

FDB clusterëŠ” cluster-wide orchestrationê³¼ system metadataë¥¼ ê´€ë¦¬í•˜ëŠ” control planeê³¼, transaction processingê³¼ data planeì„ ë‹´ë‹¹í•˜ëŠ” data planeìœ¼ë¡œ êµ¬ì„±ëœë‹¤.

![The architecture and the transaction processing of FoundationDB](foundationdb/Untitled.png)

**2.3.1 Control Plane**

control planeì€ $Coordinators$ì—ì„œ critical system metadataë¥¼ ê´€ë¦¬í•œë‹¤. $Coordinators$ëŠ” Disk Paxos Groupì„ í˜•ì„±í•˜ê³  singleton $ClusterController$ë¥¼ ì„ íƒí•œë‹¤. $ClusterContoller$ëŠ” clusterì˜ ëª¨ë“  ì„œë²„ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³ , singletonì¸ $Sequencer, DataDistributor, Ratekeeper$ë¥¼ í• ë‹¹í•˜ê³ , ì–˜ë„¤ë“¤ì´ fail/crashê°€ ìƒê¸°ë©´ ë‹¤ì‹œí• ë‹¹í•œë‹¤. $Sequencer$ëŠ” transactionì— read, commit versionì„ í• ë‹¹í•œë‹¤. $DataDistributor$ëŠ” failureë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³ , $StorageServer$ê°„ data balancingì„ ë‹´ë‹¹í•œë‹¤. $Ratekeeper$ëŠ” clusterì˜ overload protectionì„ ë‹´ë‹¹í•œë‹¤.

**2.3.2 Data Plane**

FDBëŠ” readê°€ ì£¼ë¡œ ë°œìƒí•˜ì§€ë§Œ r/wê°€ ì ê²Œë°œìƒí•˜ì—¬ low contentionì„ ê°€ì§€ì§€ë§Œ scalabilityê°€ í•„ìš”í•œ OLTP workloadë¥¼ íƒ€ê²Ÿìœ¼ë¡œ í•œë‹¤. FDBëŠ” [unbundled architecture](https://database.cs.wisc.edu/cidr/cidr2009/Paper_53.pdf) ë¥¼ ì„ íƒí–ˆë‹¤. $TS$(Distributed Transaction Management System)ì€ in-memory transaction processingì„ ìˆ˜í–‰í•˜ê³ , $LS$(Log System)ì€ $TS$ì˜ Write-Ahead-Logë¥¼ ì €ì¥í•˜ê³ , $SS$(Distributed Storage System)ì€ dataë¥¼ ì €ì¥í•˜ê³  readë¥¼ ì²˜ë¦¬í•œë‹¤.
$TS$ëŠ” transaction processingì„ ì œê³µí•˜ê³  $Sequencer, Proxies, Resolvers$ë¡œ êµ¬ì„±ë˜ë©° ì´ ì…‹ ëª¨ë‘ stateless processì´ë‹¤. $LS$ëŠ” ì—¬ëŸ¬ $LogServers$ë¡œ êµ¬ì„±ë˜ê³ , $SS$ëŠ” ë§ì€ $StorageServers$ê°€ ë¶€íŠ¼ã„´ë‹¤.

$Sequencer$ëŠ” read versionê³¼ commit versionì„ ê° transactionì— í• ë‹¹í•˜ê³  $Proxies, Resolvers, LogServers$ë¥¼ ë§Œë“œëŠ” ì—­í• ì„ í•œë‹¤. $Proxy$ëŠ” MVCC read versionì„ clientì—ê²Œ ì „ë‹¬í•˜ê³ , transaction commit orchestrationì„ ìˆ˜í–‰í•œë‹¤. $Resolver$ëŠ” transaction conflict checkì„ ìˆ˜í–‰í•œë‹¤. $LogServer$ëŠ” ê° queueê°€ $StorageServer$ì— WALë¥¼ ì €ì¥í•˜ëŠ” replicated, sharded, persistent queue ì—­í• ì´ë‹¤.

$SS$ëŠ” ë§ì€ client readë¥¼ ì„œë¹™í•˜ëŠ” $StorageServer$ë¡œ êµ¬ì„±ë˜ê³  ê° $StorageServer$ëŠ” ì—°ì†ëœ key rangeê°™ì€ data shardë¥¼ ì €ì¥í•œë‹¤. $StorageServer$ëŠ” systemì—ì„œ ê°€ì¥ ë§ì€ process ìˆ˜ë¥¼ ì°¨ì§€í•˜ê³  í•¨ê»˜ distributed B-Treeë¥¼ í˜•ì„±í•œë‹¤. í˜„ì¬ ê° $StorageServer$ì˜ storage engineì€ SQLiteì—ì„œ defer deletion, async programmingì„ ì§€ì›í•˜ê³ , range clearë¥¼ ë¹ ë¥´ê²Œ í•œ ì»¤ìŠ¤í…€ ë²„ì „ì„ ì“°ê³  ìˆë‹¤.

**2.3.3 Read-Write Separation and Scaling**

FDBì˜ processëŠ” ì„œë¡œ ë‹¤ë¥¸ roleì„ í• ë‹¹ë°›ê³  DBëŠ” ê° roleì— í•´ë‹¹ í•˜ëŠ” process ìˆ˜ë¥¼ ëŠ˜ë¦¬ëŠ” ê²ƒìœ¼ë¡œ scale outí•œë‹¤. ì´ê±´ write scalingê³¼ read scalingì„ ë¶„ë¦¬í• ìˆ˜ ìˆê²Œ í•´ì¤¬ë‹¤. clientëŠ” $StorageServer$ë¡œ ì§ì ‘ read ìš”ì²­ì„ ë„£ìœ¼ë¯€ë¡œ read scaleì€ $StorageServer$ìˆ˜ì™€ ë¹„ë¡€í•œë‹¤. writeëŠ” $TS, LS$ì˜ $Proxies, Resolvers, LogServers$ì˜ ìˆ˜ì™€ ë¹„ë¡€í•œë‹¤. MVCCë¥¼ ì“°ì§€ ì•ŠëŠ” write scalingì´ $StorageServer$ì™€ ë…ë¦½ì ìœ¼ë¡œ ëŒë„ë¡ í•˜ê¸° ìœ„í•´ì„œ MVCC dataëŠ” $SS$ì— ì €ì¥ëœë‹¤. control planeì˜ singleton process($Cluster Controller, Sequencer$ ë“±)ê³¼ $Coordinators$ëŠ” metadata operationë§Œ ìˆ˜í–‰í•˜ë¯€ë¡œ ë³‘ëª©ì´ ìƒê¸°ì§€ ì•ŠëŠ”ë‹¤

**2.3.4 Bootstrapping**

FDBëŠ” ë‹¤ë¥¸ ì„œë¹„ìŠ¤ë“±ì˜ external dependencyê°€ ì—†ë‹¤. ëª¨ë“  user dataì™€ ëŒ€ë¶€ë¶„ system data(`0xFF` prefixë¡œ ì‹œì‘í•˜ëŠ” keyë“¤ì´ system data)ëŠ” $StorageServer$ì— ì €ì¥ëœë‹¤. $StorageServer$ì— ëŒ€í•œ metadataëŠ” $LogServer$ì— ì €ì¥ëœë‹¤. $LogServer$ì˜ metadataëŠ” ëª¨ë“  $Coordinators$ì— ì €ì¥ëœë‹¤. $Coordinators$ë¥¼ Disk Paxos Groupìœ¼ë¡œ ì‚¬ìš©í•˜ë¯€ë¡œ serverë“¤ì€ $ClusterController$ê°€ ì—†ì„ê²½ìš° $ClusterController$ë¡œ ìŠ¹ê²©í•˜ëŠ”ê²ƒì„ ì‹œë„í•œë‹¤. ìƒˆë¡œ ì„ ì¶œëœ $ClusterController$ëŠ” ìƒˆ $Sequencer$ë¥¼ í• ë‹¹í•˜ê³  $Sequencer$ëŠ” $Coordinator$ì— ì €ì¥ëœ old $LS$ configë¥¼ ì½ê³  ìƒˆ $TS, LS$ë¥¼ ìƒì„±í•œë‹¤. old $LS$ì—ì„œ $Proxies$ëŠ” ëª¨ë“  $StorageServer$ì™€ ê´€ë ¨ëœ ì •ë³´ ë“±ì˜ system metadataë¥¼ ë³µêµ¬í•œë‹¤. $Sequencer$ëŠ” new $TS$ê°€ recoveryë¥¼ ëë‚¼ë•Œê¹Œì§€(Section 2.4.4) ê¸°ë‹¤ë¦¬ê³ , new $LS$ configë¥¼ ëª¨ë“  $Coordinators$ì—ê²Œ ì „ë‹¬í•œë‹¤. ì´ê²Œ ì™„ë£Œë˜ë©´ new transaction systemì€ readyìƒíƒœê°€ ëœë‹¤.

**2.3.5 Reconfiguration**

$TS,LS$ì— failureê°€ ë°œìƒí•˜ê±°ë‚˜ DB config changeê°€ ìƒê¸¸ë•Œë§ˆë‹¤ reconfiguration processëŠ” $TS$ê°€ ìƒˆ config, ì¦‰ clean stateê°€ ë˜ë„ë¡ í•œë‹¤. íŠ¹íˆ $Sequencer$ processëŠ” $Proxies, Resolvers, Logservers$ì˜ healthy checkì„ í•œë‹¤. ìœ„ processë“¤ì´ failí•˜ê±°ë‚˜ DB configê°€ ë°”ë€Œë©´ $Sequencer$ processëŠ” ì¢…ë£Œëœë‹¤. ê·¸ëŸ¼ $ClusterController$ëŠ” $Sequencer$ì˜ failureë¥¼ ê°ì§€í•˜ê³  new $Sequencer$ë¥¼ í• ë‹¹í•˜ì—¬ ìœ„ì˜ bootstrapping processë¥¼ ê±°ì³ new $TS, LS$ instanceë¥¼ ë§Œë“ ë‹¤. ì´ ë°©ì‹ìœ¼ë¡œ transaction processingì€ ì—¬ëŸ¬ epochë¡œ ë‚˜ë‰˜ê³ , ê° epochëŠ” ê³ ìœ í•œ $Sequencer$ processê°€ ìˆëŠ” $TS$ì˜ ì„¸ëŒ€ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤ (ë­”ë§..)

### 2.4 Transaction Management

**2.4.1 End-to-end Transaction Processing**

Figure 1ì— ë‚˜ì˜¨ê²ƒì²˜ëŸ¼ client transactionì€ read version(timestamp)ë¥¼ ì–»ê¸° ìœ„í•´ $Proxies$ì¤‘ í•˜ë‚˜ì™€ í†µì‹ í•˜ë©´ì„œ ì‹œì‘í•œë‹¤. $Proxy$ëŠ” $Sequencer$ì—ê²Œ ì´ì „ transactionì˜ commit versionë³´ë‹¤ í° read versionì„ ë¬¼ì–´ë³´ê³  ê·¸ ê°’ì„ clientì—ê²Œ ë¦¬í„´í•œë‹¤. clientëŠ” $StorageServers$ë¡œ read versionê³¼ í•¨ê»˜ readìš”ì²­ì„ 1+íšŒ ë‚ ë¦°ë‹¤ (ë¬¼ë¡  ì•ˆë‚ ë¦´ìˆ˜ë„ìˆìŒ). Client writeì€ clusterì™€ í†µì‹ í•˜ì§€ ì•Šê³  client bufferì— ë‚¨ê¸´ë‹¤. commitì‹œì ì— clientëŠ” read write set(key range)ì„ í¬í•¨í•œ transaction dataë¥¼ $Proxies$ì¤‘ í•˜ë‚˜ì— ë³´ë‚´ê³  $Proxy$ê°€ commit/abort ì‘ë‹µì„ ì¤„ë•Œê¹Œì§€ ê¸°ë‹¤ë¦°ë‹¤. transactionì´ commitë ìˆ˜ ì—†ìœ¼ë©´ clientëŠ” ì²˜ìŒë¶€í„° transactionì„ ë‹¤ì‹œ ì‹œì‘í•  ìˆ˜ ìˆë‹¤.

$Proxy$ëŠ” client transactionì„ ì»¤ë°‹í• ë•Œ 3ê°€ì§€ ìŠ¤í…ì„ ê±°ì¹œë‹¤. ì²«ì¨°ë¡œ $Sequencer$ì—ê²Œ transaction dataì— ìˆëŠ” read version(readìš”ì²­í• ë•Œ $StorageServers$ê°€ ë¦¬í„´?)ì´ë‚˜ commit($Sequencer$ê°€ transaction ì‹œì‘í• ë•Œ ë°œê¸‰í•´ì¤€ê²ƒ)ë²„ì „ë³´ë‹¤ ë” í° commit versionì„ ìš”ì²­í•œë‹¤. $Sequencer$ëŠ” ìµœëŒ€ 1M versions per secì˜ ì†ë„ë¡œ commit versionì„ ì˜¬ë¦°ë‹¤. $Proxy$ëŠ” transaction ì •ë³´ë¥¼ range-partitioned $Resolvers$ì—ê²Œ ì „ë‹¬í•œë‹¤(ì—¬ëŸ¬ partitionì— ì ‘ê·¼í•˜ë©´ ì—¬ëŸ¬ $Resolvers$ê°€ ì°¸ì—¬). $Resolver$ëŠ” FDBì˜ $read-write$ conflictë¥¼ í™•ì¸í•˜ëŠ” ê²ƒìœ¼ë¡œ optimistic concurrency controlì„ ìˆ˜í–‰í•œë‹¤. ëª¨ë“  $Resolvers$ê°€ no conflictì„ ë¦¬í„´í•˜ë©´ transactionì€ final commit stageë¡œ ê°ˆ ìˆ˜ ìˆì§€ë§Œ conflictì´ í•˜ë‚˜ë¼ë„ ìƒê¸°ë©´ $Proxy$ëŠ” transactionì„ abortì²˜ë¦¬í•œë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ committed transactionì€ persistenceë¥¼ ìœ„í•´ $LogServers$ë¡œ ì „ë‹¬ëœë‹¤. transactionì€ ëª¨ë“  $LogServers$ê°€ $Proxy$ì—ê²Œ ì‘ë‹µí•˜ê³  $Proxy$ê°€ $Sequencer$ì—ê²Œ committed versionì„ ì•Œë ¤ì£¼ê³ (ë‹¤ìŒ transactionì´ ì´ commitì´í›„ì˜ read versionì„ ê°€ì§€ë„ë¡ í•˜ê¸° ìœ„í•¨) clientì—ê²Œ ë¦¬í„´í•˜ë©´ commitì´ ì™„ë£Œëœë‹¤. ë™ì‹œì— $StorageServers$ëŠ” ì§€ì†ì ìœ¼ë¡œ $LogServers$ë¡œë¶€í„° mutation logë¥¼ ë°›ì•„ diskì— updateë¥¼ ìˆ˜í–‰í•œë‹¤.

FDBëŠ” $read-write\ tranasaction$ë¿ë§Œì•„ë‹ˆë¼ $read-only\ transactions$ì™€ $snapshot\ reads$ë„ ì§€ì›í•œë‹¤. FDBì˜ read-only transactionì€ serializable(íŠ¹ì • read versionìœ¼ë¡œ ì½ê¸°)í•˜ë©° MVCCë¡œ ì„±ëŠ¥ë„ ë‚˜ì˜ì§€ ì•Šìœ¼ë©°, clientëŠ” DBì™€ í†µì‹  ì—†ì´ ì´ transactionë“¤ì„ commití•  ìˆ˜ ìˆë‹¤. íŠ¹íˆ ëŒ€ë¶€ë¶„ì˜ transactionì´ read-onlyë¡œ ë™ì‘í•˜ê¸° ë•Œë¬¸ì— read-only transactionì€ ë§ì´ ì“°ì¸ë‹¤. Snapshot readëŠ” conflictì„ ì¤„ì´ëŠ”ê²ƒ(concurrent writeì´ snapshot readì™€ conflictì´ ë°œìƒí•˜ì§€ì•ŠìŒ)ìœ¼ë¡œ isolationì„ ì™„í™”í•œë‹¤.

**2.4.2 Support Strict Serializability**

FDBëŠ” OCCì™€ MVCCë¥¼ í•©ì³ì„œ SSI(Serializable Snapshot Isolation)ì„ êµ¬í˜„í–ˆë‹¤. Transaction $T_x$ëŠ” read versionê³¼ commit versionì„ $Sequencer$ë¡œë¶€í„° ë°›ì•„ì˜¤ëŠ”ë° read versionì€ $T_x$ê°€ ì‹œì‘í• ë•Œì˜ committed versionë³´ë‹¤ í° ê°’ì„ ë³´ì¥í•˜ê³ , commit versionì€ ê¸°ì¡´ì˜ read/commit versionë³´ë‹¤ í° ê°’ì´ë‹¤. commit versionì€ transactionì— ëŒ€í•œ serial historyê°€ ë˜ê³  LSN(Log Sequence Number)ì˜ ì—­í• ì„ í•œë‹¤. $T_x$ê°€ ëª¨ë“  ì´ì „ committed transactionì˜ ê²°ê³¼ë¥¼ ë³´ê²Œ ë˜ë¯€ë¡œ FDBëŠ” strict serializabilityë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤. LSNê°„ gapì´ ì—†ë„ë¡ í•˜ê¸° ìœ„í•´ $Sequencer$ëŠ” commitë²„ì „ê³¼ ì§ì „ commit version (previous LSN)ì„ í•¨ê»˜ ë¦¬í„´í•œë‹¤. $Proxy$ëŠ” LSNê³¼ previous LSNì„ $Resolver$ì™€ $LogServers$ì—ê²Œ ì „ë‹¬í•˜ì—¬ LSNì˜ ìˆœì„œì— ë”°ë¼ transactionì„ serialí•˜ê²Œ ì²˜ë¦¬í• ìˆ˜ ìˆë„ë¡ í•œë‹¤. $StorageServers$ëŠ” $LogServers$ë¡œë¶€í„° ë¡œê·¸ë¥¼ ë°›ì„ë•Œë„ LSNìˆœì„œëŒ€ë¡œ ë°›ëŠ”ë‹¤.

![Check conflicts for transaction Tx](foundationdb/Untitled1.png)

Algorithm 1ì€ $Resolvers$ì˜ lock-free conflict detection algorithmì„ ë³´ì—¬ì¤€ë‹¤. ê° $Resolver$ëŠ” committed transactionì´ ìµœê·¼ì— ìˆ˜ì •í•œ key rangeì— ëŒ€í•œ $lastCommit$ historyì™€ commit versionì„ ìœ ì§€í•œë‹¤. $T_x$ì— ëŒ€í•œ commit requestëŠ” modified key rangesì¸ $R_w$ì™€ read key rangeì¸ $R_r$ë¡œ êµ¬ì„±ëœë‹¤. line 1-5ì—ì„œ read set $R_r$ì´ ê° rangeì— ëŒ€í•´ concurrent committed transactionê³¼ ì¶©ëŒì´ ìƒê²¼ëŠ”ì§€(line4) í™•ì¸í•œë‹¤. line 6-7ì—ì„œ read-write conflictì´ ì—†ìœ¼ë©´ $Resolvers$ëŠ” commitì„ ìˆ˜ë½í•˜ê³  write set $R_w$ì˜ modified key rangeì— ëŒ€í•´ commit versionì„ ì—…ë°ì´íŠ¸í•œë‹¤. ì‹¤ì œë¡œ $lastCommit$ì€ versionì„ í™œìš©í•œ probabilistic SkipList structureë¥¼ ê°€ì§„ë‹¤.

$write-snapshot \ isolation$ ([eurosys â€˜12](https://dl.acm.org/doi/10.1145/2168836.2168853))ì—ì„œ  $R_r$ì„ í™•ì¸í•œë’¤ì— timestampë¥¼ í• ë‹¹í•˜ëŠ”ê²ƒê³¼ ë‹¤ë¥´ê²Œ FDBëŠ” conflict detectionì´ì „ì— commit versionì„ ê²°ì •í•œë‹¤. ì´ê±´ FDBê°€ versioní• ë‹¹ê³¼ conflict detectionì„ batchë¡œ ì“¸ìˆ˜ìˆê²Œ í•´ì¤€ë‹¤.

ì „ì²´ key spaceëŠ” $Resolvers$ë¡œ ìª¼ê°œì§€ë¯€ë¡œ read-write conflict detection algorithmì€ ë³‘ë ¬ë¡œ ìˆ˜í–‰ëœë‹¤. transactionì€ ëª¨ë“  $Resolvers$ê°€ transactionì„ ìˆ˜ë½ í•´ì•¼ commití•  ìˆ˜ ìˆë‹¤. aborted transactionì€ ì¼ë¶€ $Resolvers$ì—ì„œ ìˆ˜ë½ ë  ìˆ˜ ìˆê³  $lastCommit$ historyì— ë°˜ì˜ë  ìˆ˜ ìˆëŠ”ë° ì´ê±´ ë‹¤ë¥¸ transactionë“¤ì´ conflictì´ ìƒê¸°ê²Œ ë§Œë“ ë‹¤(false positive, íƒ€ì´ë° ì´ìŠˆë¡œ sequencerê°€ ì–´ë–¤ resolverì—ì„  acceptí•œë’¤ ë‹¤ë¥¸ resolverì—ì„  rejectë˜ëŠ” commit versionì„ ì¤€ ê²½ìš°? ì´ transactionì˜ commit versionì€ acceptëœì´í›„ì— ë‚ ì•„ê°€ë‹ˆê¹Œ..). ì‹¤ì œë¡œ productionì—ì„œëŠ” ë°œìƒí•˜ì§„ ì•Šì•˜ëŠ”ë° transaction key rangeê°€ ì¼ë°˜ì ìœ¼ë¡œ í•œ $Resolver$ì—ê²Œë§Œ ê°€ê¸° ë•Œë¬¸ì´ë‹¤. ë˜í•œ ëª¨ë“  modified keysëŠ” MVCC windowê°€ ì§€ë‚˜ë©´ expireë˜ë¯€ë¡œ false positiveëŠ” MVCC window time(5s)ì´ë‚´ì—ì„œë§Œ ìƒê¸´ë‹¤. ë˜í•œ $Resolvers$ì˜ key rangeëŠ” load balancingì— ì˜í•´ ë™ì ìœ¼ë¡œ ì¡°ì •ëœë‹¤.

ìœ„ì™€ ê°™ì€ OCC designì€ lockì„ ì–»ê³  ë°˜ë‚©í•˜ëŠ” ë³µì¡í•œ ë¡œì§ì„ í”¼í•´ì„œ $TS, SS$ê°„ interactionì„ ê°„ë‹¨í•˜ê²Œ ë§Œë“ ë‹¤. ë¬¼ë¡  ì—¬ê¸°ì„œ $Resolvers$ì— commit historyë¥¼ ë‚¨ê²¨ì•¼í•˜ëŠ” trade offëŠ” ìˆë‹¤. ë‹¤ë¥¸ ë‹¨ì ì€ transactionì´ commitë˜ëŠ”ê±¸ ë³´ì¥í•˜ì§€ ëª»í•˜ëŠ” ê²ƒì´ ìˆë‹¤. multi-tenant production workload íŠ¹ì„±ìƒ transaction conflictëŠ” 1%ë¯¸ë§Œì´ê³  OCCëŠ” ì˜ ë™ì‘í•œë‹¤. conflictì´ ì¼ì–´ë‚˜ë©´ clientëŠ” transactionì„ ë‹¤ì‹œ ì‹œì‘í•˜ê¸°ë§Œ í•˜ë©´ ëœë‹¤. (clientì…ì¥ì—ì„œ tail latencyê´€ë¦¬ê°€ ì¢€ í˜ë“¤ì–´ì§ˆë“¯í•œ?)

**2.4.3 Logging Protocol**

![Proxy writes a client mutation to LogServers after sequencing and resolution, Later, the mutation will be asynchronously replicated to StorageServers](foundationdb/Untitled2.png)

$Proxy$ê°€ transaction commitì„ ì²˜ë¦¬í•œ ë’¤ log messageëŠ” ëª¨ë“  $LogServers$ë¡œ broadcastëœë‹¤. Figure 2ì—ì„œ $Proxy$ëŠ” ê°–ì•„ ì²˜ìŒ in-memory shard mapì—ì„œ modified key rangeì— í•´ë‹¹í•˜ëŠ” $StroageServers$ë¥¼ ì°¾ëŠ”ë‹¤. ê·¸ ë‹¤ìŒ $Proxy$ëŠ” $StorageServer$ `1, 4, 6`ì— mutation tagë¥¼ ë‚¨ê¸´ë‹¤(ê° $LogServer$ëŠ” preferred $StorageServer$ê°€ ìˆë‹¤). mutationì€ preferred $LogServers$ (`1, 4`)ì™€, $LogServer$ `3` ì€ replication requirementë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì „ë‹¬ëœë‹¤. ë‚˜ë¨¸ì§€ $LogServers$ëŠ” empty message bodyë¥¼ ë°›ëŠ”ë‹¤(ë˜ì§ˆ í•„ìš”ê°€ ìˆë‚˜..). log message headerëŠ” LSN, previous LSNê³¼ $Proxy$ì˜ KCV(Known Commited Version)ì„ í¬í•¨í•œë‹¤. $LogServers$ëŠ” log dataê°€ durableí•´ì§€ë©´ $Proxy$ì—ê²Œ ì‘ë‹µì„ ë³´ë‚´ê³ , $Proxy$ëŠ” ëª¨ë“  $LogServers$ì—ê²Œ ì‘ë‹µì„ë°›ìœ¼ë©´ ìì‹ ì˜ KCVë¥¼ ì´ transactionì˜ LSNìœ¼ë¡œ ì—…ë°ì´íŠ¸í•œë‹¤.

$LS$ì—ì„œ $SS$ë¡œ redo logë¥¼ ì „ë‹¬í•˜ëŠ”ê±´ commit pathì—ì„œ í•˜ì§€ì•Šê³  backgroundë¡œ ì§„í–‰í•œë‹¤. $StorageServers$ëŠ” $LogServers$ì—ì„œ redo logê°€ durableí•´ì§€ê¸° ì „ë¶€í„° aggressiveí•˜ê²Œ redo logë¥¼ ê°€ì ¸ì˜¤ëŠ”ë°, ì´ê±´ multi-version readì— ëŒ€í•œ ì„œë¹™ì„ low latencyë¡œ í•˜ê¸° ìœ„í•œ ì„ íƒì´ë‹¤. production clusterì—ì„œ 12ì‹œê°„ë™ì•ˆ $LogServers$ì™€ $TimeServers$ì˜ time lagì€ avgê°€ 4msì •ë„ì´ë‹¤. lagì´ ì‘ìœ¼ë¯€ë¡œ clientì˜ read requestë¥¼ $StorageServers$ë¡œ ë³´ë‚¼ ë•Œ requested version (latest committed data)ëŠ” ëŒ€ë¶€ë¶„ $StorageServer$ì— ì´ë¯¸ ë„ì°©í•´ìˆë‹¤. ë§Œì•½ delayë¡œ dataê°€ unavailableí•˜ë©´ clientëŠ” ê¸°ë‹¤ë¦¬ê±°ë‚˜, ë‹¤ë¥¸ replicaë¡œ ìš”ì²­ì„ ë³´ë‚¸ë‹¤ ([The Tail at Scale](https://cseweb.ucsd.edu/classes/sp18/cse124-a/post/schedule/p74-dean.pdf)). ë‘ë²ˆì§¸ ìš”ì²­ë„ timeoutì´ ìƒê¸°ë©´ clientëŠ” retryable errorë¥¼ ë°›ê³  transactionì„ ì¬ì‹œì‘ í•œë‹¤.

ëª¨ë“  log dataê°€ $LogServers$ì—ì„œ durableí•˜ë¯€ë¡œ $StorageServers$ëŠ” updateë¥¼ in memory bufferì— ë‹´ì•„ë‘ê³  longer delayë¡œ dataë¥¼ batch writeí•´ì„œ IO efficiencyë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. agressiveí•˜ê²Œ redo logë¥¼ ê°€ì ¸ì˜¤ëŠ”ê²ƒì€ semi-committed updateë¥¼ ì˜ë¯¸í•œë‹¤. ì¦‰ recoveryë™ì•ˆ aborted transactionì˜ mutationì€ rollbackì‹œì¼œì¤˜ì•¼í•œë‹¤ (ì£¼ë¡œ $LogServers$ failureë•Œë¬¸, Section 2.4.4).

**2.4.4 Transaction System Recovery**

ê¸°ì¡´ DBMSëŠ” period, coarse-grained checkpoint, WALê¸°ë°˜ì˜ ARIES transaction protocolì„ ì“´ë‹¤. recoveryë™ì•ˆ ê¸°ì¡´ DBMSëŠ” last checkpointì—ì„œ red log recordë¥¼ ê°€ì ¸ì™€ì„œ data pageì— re-applyì‹œí‚¨ë‹¤. ì´ê±´ databaseê°€ point of failureì—ì„œ consistent stateë¥¼ ê°€ì§€ê²Œ í•˜ê³ , crashë•Œì˜ in-flight transactionì€ undo logë¥¼ í†µí•´ rollbackí•˜ê²Œ í•´ì¤€ë‹¤.

FDBì—ì„œ recoveryëŠ” ì €ë ´í•˜ê²Œ ë§Œë“œëŠ”ê±¸ ëª©í‘œë¡œ í–ˆë‹¤. checkpointê°€ ì—†ê³ , recoveryë™ì•ˆ redo/undo logë¥¼ re-applyí• í•„ìš”ë„ ì—†ë‹¤. transactional databaseì˜ principleì„ ì—„ì²­ ë‹¨ìˆœí™”í•´ì„œ redo log processingì´ normal log forward pathì—ì„œ ì§„í–‰ë˜ë¯€ë¡œ ê°€ëŠ¥í• ìˆ˜ ìˆì—ˆë‹¤. $StorageServers$ëŠ” ì–¸ì œë‚˜ $LogServers$ì—ì„œ logë¥¼ ë°›ì•„ backgroundë¡œ applyë¥¼ í•˜ë¯€ë¡œ redo log processingê³¼ recoveryë¥¼ ë””ì»¤í”Œë§ ì‹œì¼°ë‹¤. recovery processëŠ” failureë¥¼ ê°ì§€í•˜ëŠ”ê²ƒìœ¼ë¡œë¶€í„° ì‹œì‘í•´ì„œ, new transaction systemì„ ë„ìš´ ë’¤ old $LogServers$ê°€ ë”ì´ìƒ í•„ìš”ì—†ì–´ì§€ë©´(logë¥¼ ë‹¤ ë°›ìœ¼ë©´?) ì¢…ë£Œëœë‹¤. new transaction systemì€ old $LogServers$ì— ëª¨ë“  dataê°€ ìˆì–´ë„ transactionì„ ìˆ˜ë½í• ìˆ˜ ìˆëŠ”ë°, recoveryê°€ redo logì˜ ë ì§€ì ì„ ì°¾ê³  $StorageServers$ì—ì˜í•´ logê°€ re-apply ë˜ê¸°ë•Œë¬¸ì— ê°€ëŠ¥í•˜ë‹¤. (ì´í•´x)

ê° epoch(ì—¬ê¸°ì„œ EpochëŠ” failureì™€ ë‹¤ìŒ failiure ì‚¬ì´, ì¦‰ MTBF)ì—ì„œ $Sequencer$ëŠ” ëª‡ê°œ ìŠ¤í…ìœ¼ë¡œ recoveryë¥¼ ì‹¤í–‰í•œë‹¤. ì²«ì§¸ë¡œ $Sequencer$ëŠ” $Coordinators$ë¡œë¶€í„° previous transaction system state(config)ë¥¼ ì½ê³ , ë‹¤ë¥¸ $Sequencer$ processê°€ ë™ì‹œì— recoveryë¥¼ í•˜ì§€ ëª»í•˜ë„ë¡ ë½ì„ ê±´ë‹¤. ê·¸ ë‹¤ìŒ $Sequencer$ëŠ” ëª¨ë“  old $LogServers$ì—ëŒ€í•œ ì •ë³´ë¥¼ í¬í•¨í•˜ê³ ìˆëŠ” previous transaction system stateë¥¼ ë³µêµ¬í•˜ê³  old $LogServers$ê°€ transactionì„ ë°›ëŠ”ê²ƒì„ ë©ˆì¶”ê²Œ í•œ ë’¤, new $Proxies, Resolvers, LogServers$ë¥¼ ë„ìš´ë‹¤. preivous $LogServers$ê°€ ë©ˆì¶”ê³  new transaction systemì´ ë„ì›Œì§€ë©´ $Sequencer$ëŠ” coordinated stateë¥¼ current transaction system stateì— writeí•œë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ $Sequencer$ê°€ new transaction commitì„ ë°›ê²Œëœë‹¤.

$Proxies,Resolvers$ê°€ statelessì´ë¯€ë¡œ ì–˜ë„¤ë“¤ì˜ recoveryëŠ” í• ì¼ì´ ì—†ë‹¤. í•˜ì§€ë§Œ $LogServers$ëŠ” committed transactionì— ëŒ€í•œ logë¥¼ ì €ì¥í•˜ë¯€ë¡œ ëª¨ë“  previous committed transactionì´ $StorageServers$ì—ì„œ durable, retrievable í•˜ê²Œ ë³´ì¥í•´ì•¼ í•œë‹¤. ì¦‰ $Proxies$ê°€ commit responseë¥¼ ë°›ì€ transactionì— ëŒ€í•´, ì´ transactionì˜ logëŠ” ì—¬ëŸ¬ $LogServers$ì— replicatedë˜ì–´ì•¼ í•œë‹¤ (configì—ë”°ë¼ì„œ)

![An illustration of RV and PEV. On the left, a Proxy sends redo logs to LogServers with a ğ¾ğ¶ğ‘‰ and the ğ¿ğ‘†ğ‘, and LogServers keep the maximum ğ¾ğ¶ğ‘‰ received. On the right, recovery uses the maximum of ğ¾ğ¶ğ‘‰ s and the minimum of ğ·ğ‘‰ s on a set of LogServers as ğ‘ƒğ¸ğ‘‰ and ğ‘…ğ‘‰ , respectively](foundationdb/Untitled3.png)

An illustration of RV and PEV. On the left, a Proxy sends redo logs to LogServers with a ğ¾ğ¶ğ‘‰ and the ğ¿ğ‘†ğ‘, and LogServers keep the maximum ğ¾ğ¶ğ‘‰ received. On the right, recovery uses the maximum of ğ¾ğ¶ğ‘‰ s and the minimum of ğ·ğ‘‰ s on a set of LogServers as ğ‘ƒğ¸ğ‘‰ and ğ‘…ğ‘‰ , respectively

old $LogServers$ì˜ recoveryëŠ” redo logì˜ ë ì§€ì (RV, Recovery Version)ì„ ê²°ì •í•˜ëŠ” ê²ƒì´ë‹¤. undo logë¥¼ rollbackí•˜ëŠ”ê²ƒì€ old $LogServers,StorageServers$ì—ì„œ RVì´í›„ì˜ dataë¥¼ ë²„ë¦¬ëŠ” ê²ƒì´ë‹¤. Figure 4ëŠ” ì–´ë–»ê²Œ $Sequencer$ê°€ RVë¥¼ ê²°ì •í•˜ëŠ”ì§€ ë³´ì—¬ì¤€ë‹¤. ì´ì „ì— ë‚˜ì˜¨ê²ƒì²˜ëŸ¼ $Proxy$ê°€ $LogServers$ì— KCV(Known Committed Version, ì¦‰ maximum LSN)ì„ piggybackí•œë‹¤. ê° $LogServer$ëŠ” ë°›ì€ maximum KCVì™€ maximum persisted LSNì¸ DV(Durable Version)ë¥¼ ìœ ì§€í•œë‹¤. recoveryë™ì•ˆ $Sequencer$ëŠ” $m$ê°œì˜ old $LogServers$ë¥¼ ë©ˆì¶”ë ¤ê³  ì‹œë„í•˜ê³ , old $LogServers$ëŠ” ê°ê°ì˜ DV, KCVë¥¼ responseë¡œ ë˜ì§„ë‹¤. $LogServers$ì˜ replication degreeëŠ” $k$ë¼ê³  í•˜ì. $Sequencer$ê°€ $m-k$ê°œë¥¼ ì´ˆê³¼í•˜ëŠ” $LogServer$ë¡œë¶€í„° replyë¥¼ ë°›ìœ¼ë©´, previous epochê°€ ê°€ì§„ committed transactionì€ responseë¡œ ë°›ì€ ëª¨ë“  KCVì˜ maxê°’ê¹Œì§€ ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´ ê°’ì´ PEV(Previous epochâ€™s End Version)ì´ ëœë‹¤. ì´ version ì´ì „ì˜ dataëŠ” fully replicatedë˜ì–´ìˆë‹¤. í˜„ì¬ epochì—ì„œ start versionì€ $PEV+1$ì´ê³  $Sequencer$ëŠ” responesë¡œ ë°›ì€ ëª¨ë“  DVì˜ minê°’ì„ RVë¡œ ì„¤ì •í•œë‹¤. $[PEV+1,RV]$ ë²”ìœ„ì— ì†í•˜ëŠ” logëŠ” $LogServer$ failureì— ëŒ€í•´ replication degreeë¥¼ ë§ì¶”ê¸° ìœ„í•´, prev epochì˜ $LogServers$ì—ì„œ copyí•´ì˜¨ë‹¤. ì—¬ê¸°ì„œ copy overheadëŠ” ëª‡ì´ˆê°„ì˜ log dataë§Œì„ í¬í•¨í•˜ë¯€ë¡œ ë§¤ìš° ì ë‹¤

ì´í›„ $Sequencer$ê°€ new transactionì„ ìˆ˜ë½í•˜ë©´, $StorageServers$ì—ê²Œ RVë³´ë‹¤ ë†’ì€ ê°’ì„ ê°€ì§€ëŠ” dataë¥¼ rollbackí•˜ë„ë¡ RVë¥¼ ì•Œë ¤ì£¼ëŠ” special recovery transactionì„ ë¨¼ì € ì‹¤í–‰í•œë‹¤. í˜„ì¬ FDB storage engineì€ unversioned SQLite B-Treeì™€ in-memory multi-versioned redo log dataë¡œ êµ¬ì„±ëœë‹¤. MVCC windowê°€ ì§€ë‚œ mutationì€ SQLiteë¡œ writeëœë‹¤. rollbackì€ ë‹¨ìˆœí•˜ê²Œ in-memory multi-versioned dataë§Œ ë²„ë¦¬ê²Œ ëœë‹¤. ê·¸ ë’¤ $StorageServers$ëŠ” new $LogServers$ë¡œë¶€í„° PEVë³´ë‹¤ ë†’ì€ dataë¥¼ pullí•˜ê²Œ ëœë‹¤.

### 2.5 Replication

FDBëŠ” $f$ failureì—ì„œë„ tolerantí•˜ê¸° ìœ„í•´ì„œ ì—¬ëŸ¬ replication strategyë¥¼ ì„ì—ˆë‹¤.

- **Metadata Replication**
control planeì˜ system metadataëŠ” Active Disk Paxosë¥¼ ì´ìš©í•´ì„œ $Coordinators$ì— ì €ì¥ëœë‹¤. $Coordinator$ quorumì´ ì‚´ì•„ìˆëŠ”í•œ metadataëŠ” fault-tolerantí•˜ë‹¤.
- **Log Replication
$Proxy$**ê°€ $LogServers$ë¡œ logë¥¼ ë˜ì§ˆ ë•Œ, ê° shareded log recoredëŠ” $k=f+1\ \ LogServers$ë¡œ synchronoously replicateëœë‹¤. ëª¨ë“  $k\ LogServers$ê°€ logì €ì¥ì— ì„±ê³µí•œ ê²½ìš°ì—ë§Œ $Proxy$ê°€ clientì—ê²Œ commit responseë¥¼ ë³´ë‚¼ ìˆ˜ ìˆë‹¤. $LogServer$ failureê°€ ìƒê¸°ë©´ transaction system recoveryê°€ ë™ì‘í•œë‹¤ (Section 2.4.4)
- **Storage Replication
ëª¨ë“  shardëŠ” $k=f+1\ \ Storage Servers$**ë¡œ asynchronously replicateëœë‹¤. ì´ replicateë˜ëŠ” sharedë“¤ì„ $team$ì´ë¼ ë¶€ë¥¸ë‹¤. $StorageServer$ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë§ì€ shardë¥¼ ê°€ì ¸ì„œ dataê°€ ë§ì€ teamì— evenly-distributedëœë‹¤.  $StorageServer$ failureëŠ” $DataDistributer$ê°€ failureê°€ ìƒê¸´ teamì—ì„œ ë‹¤ë¥¸ helaty teamìœ¼ë¡œ dataë¥¼ ì˜®ê¸°ë„ë¡ íŠ¸ë¦¬ê±°í•œë‹¤.

storage team abstractionì€ [Copyset](https://www.usenix.org/system/files/conference/atc13/atc13-cidon.pdf) policy (**[Copysets and Chainsets: A Better Way to Replicate](https://hackingdistributed.com/2014/02/14/chainsets/)**)ë³´ë‹¤ ì •êµí•˜ë‹¤. Copysetì€ k-process groupsë¡œ shardë¥¼ í• ë‹¹í•˜ëŠ”ê²ƒìœ¼ë¡œ ë™ì‹œì— ì—¬ëŸ¬ process failureì—ì„œ data lossê°€ ìƒê¸¸ ê°€ëŠ¥ì„±ì„ ì¤„ì¸ë‹¤. ê·¸ë ‡ì§€ì•Šìœ¼ë©´ k-process failureëŠ” data lossê°€ëŠ¥ì„±ì´ ë†’ì•„ì§„ë‹¤. FDBì—ì„œ teamì€ ì—¬ëŸ¬ dimensionìœ¼ë¡œ ë³¼ ìˆ˜ìˆë‹¤. ê° replica groupì€ ê°™ì€ ì‹œê°„ì— ì—¬ëŸ¬ ì œì•½ì„ ë§Œì¡±í•´ì•¼ í•œë‹¤. ì˜ˆë¥¼ë“¤ì–´ clusterëŠ” ì—¬ëŸ¬ hostë¥¼ ê°€ì§€ê³ , hostëŠ” ì—¬ëŸ¬ processë¥¼ ì‹¤í–‰í•œë‹¤. ì¦‰ failureê°€ host levelì—ì„œ ì¼ì–´ë‚˜ë©´ ì—¬ëŸ¬ processì—ê²Œ ì˜í–¥ì„ ë¯¸ì¹œë‹¤. ë”°ë¼ì„œ replica groupì€ ê°™ì€ hostì˜ processë“¤ë¡œ ë“¤ì–´ê°€ì„ ì•ˆëœë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì´ëŸ° placementëŠ” replica groupì— ìµœëŒ€ í•˜ë‚˜ì˜ processê°€ $fault \ domain$(rackì´ë‚˜ AZ)ì— ë†“ì¼ ìˆ˜ ìˆë„ë¡ ë³´ì¥í•´ì•¼ í•œë‹¤.

ë”°ë¼ì„œ FDBëŠ” simultaneous failureì—ì„œ data lossë¥¼ ì¤„ì´ê¸° ìœ„í•´ hierarchical replication policyë¥¼ ë§Œë“¤ì—ˆë‹¤. íŠ¹íˆ hostì™€ process levelì˜ replica setì„ ë§Œë“¤ê³  ê° process groupì´ fault domain requirementì— ë§Œì¡±í•˜ëŠ” host groupì— ì†í•˜ë„ë¡ ë³´ì¥í•œë‹¤. ì´ ë°©ì‹ì€ íŠ¹ì • host groupì˜ ëª¨ë“  hostê°€ ë™ì‹œì— failí• ë•Œë§Œ data lossê°€ ìƒê¸¸ ìˆ˜ ìˆë‹¤. ì¦‰ ì—¬ëŸ¬ fault domainì—ì„œ concurrent failureê°€ ë°œìƒí•´ì•¼ í•œë‹¤. fault domainì¤‘ í•˜ë‚˜ë§Œ availableí•˜ë©´ teamë§ˆë‹¤ ìµœì†Œ í•˜ë‚˜ì˜ processê°€ ì‚´ì•„ìˆê²Œ ë˜ë¯€ë¡œ data lossê°€ ì—†ë‹¤.

### 2.6 Other Optimizations

**Transaction Batching**

transaction commitì„ amortizeí•˜ê¸° ìœ„í•´ $Proxy$ ëŠ” clientì—ì„œ ë°›ì€ ì—¬ëŸ¬ transactionì„ í•œ batchë¡œ ê·¸ë£¨í•‘ì‹œí‚¤ê³  $Sequencer$ë¡œë¶€í„° single commit versionì„ ë°›ì•„ì˜¤ê³ , ì´ batchë¥¼ conflict detectionì„ ìœ„í•´ $Resolver$ì—ê²Œ ì „ë‹¬í•œë‹¤. ê·¸ ë‹¤ìŒ $Proxy$ëŠ” batchë¡œ ë¬¶ì¸ committed transactionì„ $LogServers$ì— writeí•œë‹¤. transaction batchingì€ $Sequencer$ì—ì„œ commit versionì„ ê°€ì ¸ì˜¤ëŠ” íšŸìˆ˜ë¥¼ ì¤„ì—¬ $Proxies$ê°€ $Sequencer$ì„±ëŠ¥ì— ì˜í–¥ì„ ë°›ì§€ ì•Šê³  ì´ˆë‹¹ ìˆ˜ë§Œê°œì˜ transactionì„ ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ í•´ì¤€ë‹¤. ë˜í•œ  loadê°€ ì ì„ë•Œ commit latencyë¥¼ ì¤„ì´ê¸° ìœ„í•´ batching degreeê°€ ì¤„ì–´ë“¤ê³ , loadê°€ ë§ì„ë•Œ commit throughputì„ ë†’ì´ê¸°ìœ„í•´ batching degreeë¥¼ ë™ì ìœ¼ë¡œ ëŠ˜ë¦´ ìˆ˜ ìˆë‹¤.

**Atomic Operations**

FDBëŠ” atomic add, bitwise â€œandâ€, compare-and-clera, set-versionstampê°™ì€ atomic operationì„ ì§€ì›í•˜ë¯€ë¡œ transactionì´ valueë¥¼ ì½ì§€ ì•Šê³ ë„ dataë¥¼ writeí•´ì„œ $StorageServeres$ì™€ì˜ RTTë¥¼ ì¤„ì¸ë‹¤. ë˜í•œ ê°™ì€ dataë¥¼ ì ‘ê·¼í• ë•Œ ìƒê¸°ëŠ” $read-write$ conflictì„ ì—†ì•¤ë‹¤ ($write-read$ conflictë§Œ ë°œìƒ). conflictì´ ì¤„ì–´ë“¤ê¸°ë•Œë¬¸ì— key-value pairë¥¼ counterë¡œ ì“°ëŠ”ê²ƒì²˜ëŸ¼ ìì£¼ updateë˜ëŠ”ê²½ìš°ì— ì¢‹ë‹¤. set-versionstampëŠ” keyë‚˜ valueë¥¼ transactionì˜ commit versionìœ¼ë¡œ ì—…ë°ì´íŠ¸í•œë‹¤. ì´ê±´ client applicationì´ ì¶”í›„ì— commit versionì„ ë‹¤ì‹œ ì½ì–´ì„œ client-side cachingìœ¼ë¡œ ì„±ëŠ¥í–¥ìƒì„ ì–»ì„ ìˆ˜ ìˆë‹¤.

FDB Record Layerì—ì„œ aggregate indexëŠ” atomic mutationì„ ì‚¬ìš©í•˜ì—¬ concurrent, conflict-free updateê°€ ê°€ëŠ¥í•˜ê³ , set-versionstamp operationì€ index synchronizationì—ì„œ contentionì„ ì ê²Œ ë§Œë“¤ì–´ì¤€ë‹¤.

## 3. Geo-Replication and Failover

regional failureì—ì„œë„ HAë¥¼ ì œê³µí•˜ëŠ”ê±´ perforamanceì™€ consistency ì‚¬ì´ì˜ tradeoffì´ë‹¤. sync cross-region replicationì€ strong consistencyë¥¼ ì–»ì§€ë§Œ high latencyê°€ ëœë‹¤. async replicationì€ primary regionì—ë§Œ ì €ì¥í•˜ë©´ ë˜ë¯€ë¡œ latencyê°€ ì¤„ì–´ë“¤ì§€ë§Œ failoverì‹œ data lossê°€ ìƒê¸¸ ìˆ˜ ìˆë‹¤. FDBëŠ” sync, asyncë¥¼ ì„ íƒí•  ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ ê°™ì€ regionì—ì„œë„ failure indenpendencyê°€ ë†’ì€ AZë¥¼ ì´ìš©í•˜ë©´ regional failureë¥¼ í”¼í•  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤. FDBì˜ designì€ 1) async replicationì„ í†µí•´ cross-regional write latency ì¤„ì´ê³ , 2) regionì˜ ëª¨ë“  AZì—ì„œ failureê°€ ë°œìƒí•˜ì§€ì•ŠëŠ”ë‹¤ë©´ sync replicationê°™ì€ transactional durabilityë¥¼ ì œê³µí•˜ê³ , 3) regionê°„ì— ë¹ ë¥´ê³  ìë™ì ìœ¼ë¡œ failoverë¥¼ í•˜ê³ , 4) ê±°ì˜ ìƒê¸°ì§€ ì•ŠëŠ” total regional failiureì¼ë•ŒëŠ” maunalí•˜ê²Œ failoverë¥¼ í•˜ë„ë¡ í•˜ê³  (DurabilityëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë‚®ë‹¤ê³  ë³¼ìˆ˜ìˆìŒ), 5) primary, secondary regionì—ì„œ main AZì—ì„œë§Œ full replicaê°€ í•„ìš”í•˜ë„ë¡ (ë‹¤ë¥¸ AZëŠ” full replicaì¼ í•„ìš” X) í•œë‹¤.

![A two-region replication setup for an FDB cluster. Both regions have a data center and two satellite sites.](foundationdb/Untitled4.png)

ìœ„ ê·¸ë¦¼ì€ two-region replicationì„ ë³´ì—¬ì¤€ë‹¤. ë‘ regionì€ 2ê°œì´ìƒì˜ AZ(í•˜ë‚˜ëŠ” main, DC, ë‚˜ë¨¸ì§€ëŠ” satellite)ì´ë‹¤. satelliteëŠ” log replica(redo log suffix)ë§Œ ì €ì¥í•˜ë©´ ë˜ë¯€ë¡œ resource ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì ê²Œ ì“°ì´ê³ , data centerëŠ” primary DCì¼ê²½ìš° $TS, LS,SS$, secondary DCì¼ ê²½ìš° $LS, SS$ë¥¼ ë„ì›Œì•¼ í•œë‹¤. control plane replicaëŠ” 3ê°œ ì´ìƒì˜ failure domainì— ë„ìš°ë©° ì¼ë°˜ì ìœ¼ë¡œ ìµœì†Œ 9ê°œì˜ replicaë¥¼ ë„ìš´ë‹¤. quorumì— ì˜ì¡´í•˜ëŠ”ê²ƒì€ control planeì´ one site failureì—ë„ tolerantí•˜ê²Œ í•´ì¤€ë‹¤

readëŠ” primary, secondary DCì—ì„œ ëª¨ë‘ ì„œë¹™ ê°€ëŠ¥í•˜ì§€ë§Œ, consistent readëŠ” primary DCì—ì„œë§Œ ê°€ëŠ¥í•˜ë‹¤. ëª¨ë“  client writeëŠ” primary DCì˜ $Proxies$ë¡œ ê°€ê³ , $Proxies$ëŠ” primary DCì™€ ë‹¤ë¥¸ AZ(ê°™ì€ region)ì˜ $LogServers$ì— sync persistí•´ì„œ cross-region WAN latencyë¥¼ í”¼í•œë‹¤. updateëŠ” asyncë¡œ secondary DCì˜ $LogServers$ì—ê²Œ ê°„ ë’¤ $StorageServers$ë¡œ ì €ì¥ëœë‹¤. $LogRouters$ëŠ” cross-region data transfer ì—­í• ì„ í•˜ë©° redundant corss-region transferë¥¼ í”¼í•˜ê¸° ìœ„í•œ ëª©ì ì´ë‹¤. primary DCì˜ $LogServers$ê°€ ê° log entryë¥¼ $LogRouters$ì—ê²Œ í•œë²ˆë§Œ ì „ë‹¬í•˜ê³ , $LogRouters$ëŠ” secondary DCì˜ ì—¬ëŸ¬ $LogServers$ì—ê²Œ ì „ë‹¬í•œë‹¤(ê°™ì€ AZì—ì„œ redundancyë¥¼ ê°€ì§€ê²Œ ë¨).

primary DCê°€ unavailableí•´ì§€ë©´ ìë™ìœ¼ë¡œ secondary regionì—ì„œ failoverí•œë‹¤. failoverê°€ ìƒê¸°ë©´ DC2ëŠ” log suffixë¥¼ ê°€ì§€ì§€ ì•Šê²Œ ë˜ê³  (ë­”ì˜ë¯¸??), primary regionì˜ ë‚¨ì€ $LogServers$ì—ì„œë¶€í„° ë³µêµ¬ë¥¼ ì‹œì‘í•˜ê²Œëœë‹¤.

primary regionì˜ DC1ì´ unavailableí•´ì§€ë©´ $Coordinators$ëŠ” failureë¥¼ ê°ì§€í•˜ê³  DC2ì— ìƒˆ TSë¥¼ ë„ìš´ë‹¤. ë˜í•œ DC2ì˜ Satelliteì— ìƒˆ $Logservers$ê°€ ë„ì›Œì§„ë‹¤ (region replication policyì— ë”°ë¼). recoveryë™ì•ˆ DC2ì˜ $LogRouters$ëŠ” ì ì‹œë™ì•ˆ primary satelliteì—ì„œ ë¡œê·¸ë¥¼ ë°›ì•„ì•¼ í•œë‹¤. recovery ì´í›„ primary region failureê°€ íšŒë³µë˜ë©´ DC1ì´ higher priority(ì„¤ì •ì—ë”°ë¼)ë¡œ mainì´ ë ìˆ˜ìˆê³ , íšŒë³µí•˜ì§€ëª»í•˜ë©´ secondary regionì´ mainì´ ëœë‹¤.

## 4. Simulation Testing

ë¶„ì‚°ì‹œìŠ¤í…œì—ì„œ testing, debuggingì€ ì–´ë ¤ìš°ë©´ì„œ ë¹„íš¨ìœ¨ì ì´ë‹¤. íŠ¹íˆ FDBëŠ” strong concurrency control contractê°€ ìˆê³ , ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ ìœ— layerì— corruptionì´ ìƒê¸¸ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ FDB ê°œë°œì„ ì‹œì‘í• ë•Œ end-to-end testingì„ ë„ì…í–ˆë‹¤. DBëŠ” randomized synthetic workload, fault injectionë“±ì„ í• ìˆ˜ ìˆëŠ” deterministic discrete-event simulationìœ„ì—ì„œ ë™ì‘í•˜ê²Œëœë‹¤. ì´ simulation environmentëŠ” DBì˜ ë²„ê·¸ë¥¼ ë¹ ë¥´ê²Œ ë§Œë“¤ì–´ë‚´ê³ , deteminismì„í†µí•´ ëª¨ë“  ë²„ê·¸ê°€ ì¬í˜„ê°€ëŠ¥í•˜ê³  ê³ ì¹  ìˆ˜ ìˆë„ë¡ í•œë‹¤.

### Deterministic Simulator

![The FDB deterministic simulator](foundationdb/Untitled5.png)

FDBëŠ” testingì´ ê°€ëŠ¥í•˜ë„ë¡ ì‘ì„±ë˜ì—ˆë‹¤. ëª¨ë“  DB codeëŠ” deteministicí•˜ê³  multithreaded concurrencyëŠ” ì—†ë‹¤(db nodeê°€ coreë‹¨ìœ„ë¡œ ë°°í¬ë˜ë¯€ë¡œ). ìœ„ ê·¸ë¦¼ì€ FDBì˜ simulation processë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. ëª¨ë“  non-determinsmê³¼ communicationì€ abtractë˜ì–´ìˆë‹¤ (network, disk, time, pseudo random number generator). FDBëŠ” [Flow](https://github.com/apple/foundationdb/tree/main/flow)ë¼ëŠ” CPPì— async/await like concurrency primitiveë¥¼ ë”í•œ extensionìœ¼ë¡œ ì‘ì„±ë˜ì—ˆë‹¤. FlowëŠ” Actor programming modelì„ ì œê³µí•´ì„œ, FDB server processì˜ actionë“¤ì„ Flow runtime libraryê°€ ìŠ¤ì¼€ì¤„ë§í•˜ëŠ” actorë“¤ë¡œ ì¶”ìƒí™”í•œë‹¤. simulator processëŠ” ì—¬ëŸ¬ FDB serverë¥¼ ë„ì›Œ single discrete-event simulation ì•ˆì˜ simulated networkë¥¼ í†µí•´ ì—¬ëŸ¬ FDB serverë“¤ì´ ì„œë¡œ í†µì‹ í•˜ê²Œ ëœë‹¤.  simulatorëŠ” ì—¬ëŸ¬ workloadë¥¼ ì‹¤í–‰ì‹œí‚¤ëŠ”ë°, fault injection instruction, mock application, db config change, direct intenral db invocation ë“±ì„ ìˆ˜í–‰í•œë‹¤.

### Test Oracles

FDBëŠ” simulationì—ì„œ failureë¥¼ ì°¾ê¸° ìœ„í•´ ë‹¤ì–‘í•œ test oracleì„ ì‚¬ìš©í•œë‹¤. ëŒ€ë¶€ë¶„ì˜ synthetic workloadëŠ” contractë¥¼ ê²€ì¦í•˜ê¸° ìœ„í•œ assertionrê³¼ DB propertyì´ë‹¤. assertionì€ code base ì „ì²´ë¥¼ ê²€ì‚¬í•˜ê³ , recoverabilityê°™ì€ db propertiesëŠ” failureê°€ ë°œìƒí•˜ëŠ” í™˜ê²½ì—ì„œë¶€í„° ë³µêµ¬ê°€ëŠ¥í•œìƒíƒœë¡œ ë˜ëŒë¦¬ê³ (networkê°€ ì£½ì—ˆë”° ì‚´ì•„ë‚œë‹¤ë˜ì§€), clusterê°€ ë³µêµ¬ë˜ëŠ”ì§€ í™•ì¸í•œë‹¤.

### Fault Injection

FDB simulatorëŠ” machine, rack, DC level ì˜ failure, rebootingê³¼ network fault, partition, latencyì™€ disk corruption, randomized event timeë“±ì„ injectí•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ DBê°€ íŠ¹ì • faultì—ì„œ resilencyë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³ , ë‹¤ì–‘í•œ simulationì„ í•  ìˆ˜ ìˆë‹¤. FDBëŠ” buggificationì´ë¼ í•˜ëŠ” high level fault injectionì„ í†µí•´ simulationê³¼ cooperateí•œë‹¤(testì½”ë“œì™€ targetì½”ë“œê°€ ìƒí˜¸ì‘ìš©.?).

[Swarm testing](https://www.cs.utah.edu/~regehr/papers/swarm12.pdf)ì€ simulationì˜ ë‹¤ì–‘ì„±ì„ ìµœëŒ€ë¡œ í•˜ê¸°ìœ„í•´ ì‚¬ìš©ëœë‹¤. ê° runì—ì„œëŠ” cluster size, config, worload, fault injection parameter, tuning parameterë“±ë“±ì„ randomìœ¼ë¡œ ì‹¤í–‰í•œë‹¤. (ì˜¤í”ˆì†ŒìŠ¤ [https://github.com/FoundationDB/fdb-joshua](https://github.com/FoundationDB/fdb-joshua))

conditional coverate macroëŠ” simulationì˜ íš¨ê³¼ë¥¼ í‰ê°€í•˜ê³  íŠœë‹í•œë‹¤. ì˜ˆë¥¼ë“¤ì–´ ê°œë°œìê°€ ê°€ë”í˜¸ì¶œë˜ëŠ” ì½”ë“œë¥¼ ì¶”ê°€í•˜ëŠ”ê²½ìš° simulation resultëŠ” ì–¼ë§ˆë‚˜ ë§ì€ distinct simulation runì´ í•´ë‹¹ ì¡°ê±´ì„ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸í•œë‹¤. ìˆ«ìê°€ ë„ˆë¬´ ì ìœ¼ë©´ buggification, workload, fault injectionë“±ì„ ë”í•´ì„œ ì½”ë“œê°€ í…ŒìŠ¤íŠ¸ë˜ë„ë¡ í•  ìˆ˜ ìˆë‹¤.

### Latency **to Bug Discovery**

discrete-event simulationì€ simulationì˜ CPU utilì´ ë‚®ì„ë•Œ ë‹¤ìŒ eventê°€ ë°œìƒë˜ë„ë¡ clockì„ ì›€ì§ì—¬ì„œ ë¹ ë¥´ê²Œ ì‹¤í–‰ë  ìˆ˜ ìˆë„ë¡í•œë‹¤. ë§ì€ ë¶„ì‚°ì‹œìŠ¤í…œì˜ ë²„ê·¸ëŠ” ì‹¤í–‰ë˜ëŠ”ë° ì‹œê°„ì´ ê±¸ë¦¬ê³ , ë‚®ì€ CPUì—ì„œ ì‹¤ì œë³´ë‹¤ ë” ë§ì€ ë²„ê·¸ë¥¼ ì°¾ì„ ìˆ˜ ìˆë‹¤. ë˜í•œ ì—¬ëŸ¬ simulationì„ ë™ì‹œì— ëŒë ¤ì„œ ë²„ê·¸ë¥¼ ë” ë¹ ë¥´ê²Œ ì°¾ì„ ìˆ˜ ìˆë‹¤. 

### Limitations

performance issueê°™ì€ê±´ ì•ˆì •ì ìœ¼ë¡œ ê°ì§€í• ìˆ˜ì—†ë‹¤. third party library, dependencyë‚˜ Flowë¡œ ì‘ì„±ë˜ì§€ ì•Šì€ ì½”ë“œë„ ê°ì§€ë¶ˆê°€ëŠ¥í•˜ë‹¤. ë”°ë¼ì„œ ì™¸ë¶€ ì‹œìŠ¤í…œì„ ìµœëŒ€í•œ ì ê²Œ ì“°ê³ ìˆë‹¤.

## 6. Lesson Learned

### 6.1 Architecture Design

storage layerì—ì„œ transaction systemì„ ë¶„ë¦¬í•œê±´ compute, storage resourceë¥¼ ë…ë¦½ì ìœ¼ë¡œ scalingí• ìˆ˜ìˆëŠ” ì´ì ì„ ì œê³µí•´ì¤€ë‹¤. ë˜í•œ operatorsëŠ” ë‹¤ë¥¸ instance typeì—ì„œ heterogeneous roleì„ ê°€ì§€ë¯€ë¡œ ì„±ëŠ¥ì´ë‚˜ ë¹„ìš©ìµœì í™”ì— ìœ ë¦¬í•˜ë‹¤ (coordinatorê°™ì€ì• ë“¤ì€ ë” ì ì€ resourceì‚¬ìš©). storage layerê°€ ë…ë¦½ì ìœ¼ë¡œ ìˆìœ¼ë¯€ë¡œ í˜„ì¬ëŠ” SQLiteë¥¼ ë²„ë¦¬ê³  RocksDBë¥¼ ë„ì…í•˜ë ¤ í•˜ê³ ìˆë‹¤. ìµœê·¼ì˜ ì„±ëŠ¥í–¥ìƒ í¬ì¸íŠ¸ëŠ” ê°ê° ë¶„ë¦¬ëœ Roleì— íƒ€ê²Ÿì„ ë§ì¶”ê³ ìˆë‹¤. $Sequencer$ì—ì„œ $DataDistributor, Ratekeeper$ ë¶„ë¦¬, storage cacheì¶”ê°€, $Proxies$ë¥¼ get-read-version proxy, commit proxyë¡œ ë¶„ë¦¬ ë“±.

### 6.2 Simulation Testing

ì˜ˆì „ì—” zookeeperë¥¼ ì¼ëŠ”ë° Simulation Testingìœ¼ë¡œ ë²„ê·¸ë¥¼ ì¡ì•„ë‚¸ ë’¤ Paxosë¥¼ ì§ì ‘êµ¬í˜„í–ˆë‹¤.

### 6.3 Fast Recovery

fast recoveryëŠ” availabilityë¥¼ í–¥ìƒí•˜ê¸°ë„í•˜ì§€ë§Œ upgradeë‚˜ config changeë¥¼ ë” ë¹ ë¥´ê²Œ í•´ì¤€ë‹¤. ê¸°ì¡´ì—” distributed systemì„ rolling upgradeë¥¼ í•´ì•¼í•˜ëŠ”ê²Œ ì¼ë°˜ì ì´ì—ˆë‹¤. rolling upgradeëŠ” ìµœì†Œ í•œì‹œê°„ì—ì„œ ë©°ì¹ ì´ ê±¸ë¦¬ê¸°ë„í•œë‹¤. í•˜ì§€ë§Œ FDBëŠ” ëª¨ë“  processë¥¼ ì¬ì‹œì‘í•˜ëŠ”ê²ƒìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ê³  ëª‡ì´ˆë°–ì—ê±¸ë¦¬ì§€ì•ŠëŠ”ë‹¤. ë˜í•œ upgrade pathëŠ” ë‹¤ë¥¸ versionì— ëŒ€í•œ protocolí˜¸í™˜ì„±ì„ ë‹¨ìˆœí•˜ê²Œ í•´ì¤€ë‹¤. disk dataí˜¸í™˜ì„±ë§Œ ë§ì¶”ë©´ëœë‹¤. RPC protocolë“±ì„ ê²€ì¦í•  í•„ìš”ëŠ” ì—†ë‹¤.

ë˜í•œ fast recoveryëŠ” ìë™ì ìœ¼ë¡œ ì ì¬ì ì¸ ë²„ê·¸ì—ì„œ íšŒë³µí•œë‹¤. $Sequencer$ì—ì„œ $DataDistributor$ë¥¼ ë¶„ë¦¬í–ˆì„ ë•Œ, $DataDistributor$ì—ì„œ ì•Œë ¤ì§€ì§€ ì•Šì€ ë²„ê·¸ë“¤ì„ ì°¾ì•˜ë‹¤.

### 6.4 5s MVCC Window

FDBëŠ” transaction system, storage serversì˜ memory usageë•Œë¬¸ì— 5s MVCC windowë¥¼ ì„ íƒí–ˆë‹¤. multi-version dataëŠ” $Resolver, StorageServers$ì—ì„œ 5ì´ˆê°„ ìœ ì§€ë˜ë©° ì´ê²ƒë•Œë¬¸ì— transaction sizeë„ ì œí•œí•˜ê³ ìˆë‹¤. ê²½í—˜ìƒ 5s windowëŠ” OLTP usecaseì—ì„œ ì¶©ë¶„í•˜ë‹¤. transactionì´ time limitì„ ë„˜ì–´ê°€ê²Œë˜ë©´ ì´ê±´ client applicationì´ ë¹„íš¨ìœ¨ì ìœ¼ë¡œ ë™ì‘í•˜ëŠ”ê²½ìš°ê°€ ëŒ€ë‹¤ìˆ˜ì˜€ë‹¤(readë¥¼ ë³‘ë ¬ë¡œí•˜ì§€ì•Šê³  ìˆœì°¨ì ìœ¼ë¡œí•œë‹¤ë˜ì§€).

ì¼ë¶€ transactionì€ 5sì´ìƒ ê±¸ë¦¬ê¸°ë„í•˜ëŠ”ë° ëŒ€ë¶€ë¶„ì€ smaller transactionìœ¼ë¡œ ìª¼ê°¤ìˆ˜ ìˆë‹¤. continuous backupì€ key spaceë¥¼ ìŠ¤ìº”í•˜ê³  key rangeì— ëŒ€í•œ snapshotì„ ë§Œë“ ë‹¤. 5s limitë•Œë¬¸ì— scanning processëŠ” ë” ì‘ì€ Rangeë¡œ ì‹¤í–‰ë˜ì–´ 5sì´ë‚´ì— ì™„ë£Œë˜ë„ë¡í•œë‹¤. ì‹¤ì œë¡œë„ common patternì¸ë° í•œ Transactionì€ ì—¬ëŸ¬ jobì„ ë§Œë“¤ê³  ê° jobì´ transactionì„ ìª¼ê°œì–´ ì‹¤í–‰í•œë‹¤. FDBëŠ” ì´ëŸ° íŒ¨í„´ì„ $TaskBucket$ì´ë¼ëŠ” abstractionìœ¼ë¡œ ë§Œë“¤ì—ˆê³  backup systemì´ ì‚¬ìš©í•˜ê³  ìˆë‹¤.